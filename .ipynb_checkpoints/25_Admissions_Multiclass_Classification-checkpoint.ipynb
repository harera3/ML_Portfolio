{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 25. GRADUATE ADMISSIONS: MULTICLASS CLASSIFICATION\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 7) (100, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>LOR</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  CGPA  Research  LOR  \\\n",
       "0        337          118                  4  4.5  9.65         1  4.5   \n",
       "1        324          107                  4  4.0  8.87         1  4.5   \n",
       "2        316          104                  3  3.0  8.00         1  3.5   \n",
       "3        322          110                  3  3.5  8.67         1  2.5   \n",
       "4        314          103                  2  2.0  8.21         0  3.0   \n",
       "\n",
       "   Chance of Admit  \n",
       "0                1  \n",
       "1                2  \n",
       "2                2  \n",
       "3                2  \n",
       "4                3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option(\"display.max_columns\", 99)\n",
    "pd.set_option(\"display.max_rows\", 999)\n",
    "pd.set_option('precision', 3)\n",
    "\n",
    "admission = pd.read_csv('data/Admission3_class')\n",
    "\n",
    "train, test = train_test_split(admission, test_size=0.2, random_state=42)\n",
    "X_train = train.drop('Chance of Admit', axis=1)\n",
    "y_train = train['Chance of Admit']\n",
    "X_test = test.drop('Chance of Admit', axis=1)\n",
    "y_test = test['Chance of Admit']\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "admission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    164\n",
       "2    149\n",
       "1     87\n",
       "Name: Chance of Admit, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62      , 0.67857143, 0.5       , 0.625     , 0.65064103,\n",
       "        1.        , 0.71428571],\n",
       "       [0.52      , 0.67857143, 0.75      , 0.75      , 0.55769231,\n",
       "        0.        , 1.        ],\n",
       "       [0.26      , 0.35714286, 0.5       , 0.625     , 0.54487179,\n",
       "        0.        , 0.42857143],\n",
       "       [0.48      , 0.53571429, 0.25      , 0.375     , 0.47115385,\n",
       "        0.        , 0.71428571],\n",
       "       [0.36      , 0.5       , 0.5       , 0.625     , 0.45192308,\n",
       "        1.        , 0.28571429]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training a Few Classification Models\n",
    "#### 2.i. SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_Scores: [0.75 0.75 0.67 0.71]\n",
      "Avg_Accuracy_Score: 0.72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "scores = cross_val_score(sgd_clf, X_train, y_train, cv=4, scoring=\"accuracy\")\n",
    "print('Accuracy_Scores:', scores)\n",
    "print('Avg_Accuracy_Score:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score is worse than what we got when we did binary classification. SGD classifiers can directly classify instances into multiple classes. This is done by combining multiple binary classifiers in a “one versus all” (OVA),  also known as `one-vs-the-rest (OvR)`, scheme.\n",
    "Let's try a one-vs-one strategy and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_Scores: [0.71 0.8  0.8  0.86]\n",
      "Avg_Accuracy_Score: 0.7925\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "ovo_sgd = OneVsOneClassifier(sgd_clf)\n",
    "scores = cross_val_score(ovo_sgd, X_train, y_train, cv=4, scoring=\"accuracy\")\n",
    "print('Accuracy_Scores:', scores)\n",
    "print('Avg_Accuracy_Score:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score get's better if we use the one-vs-one strategy. \n",
    "#### 2.ii. KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_Scores: [0.79 0.77 0.79 0.81]\n",
      "Avg_Accuracy_Score: 0.79\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "scores = cross_val_score(knn_clf, X_train, y_train, cv=4, \n",
    "                         n_jobs=-1, scoring=\"accuracy\")\n",
    "print('Accuracy_Scores:', scores)\n",
    "print('Avg_Accuracy_Score:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_Scores: [0.79 0.77 0.79 0.82]\n",
      "Avg_Accuracy_Score: 0.7925\n"
     ]
    }
   ],
   "source": [
    "ovo_knn = OneVsOneClassifier(knn_clf)\n",
    "scores = cross_val_score(ovo_knn, X_train, y_train, cv=4, scoring=\"accuracy\")\n",
    "print('Accuracy_Scores:', scores)\n",
    "print('Avg_Accuracy_Score:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.iii. SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_Scores: [0.79 0.77 0.82 0.9 ]\n",
      "Avg_Accuracy_Score: 0.82\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC()\n",
    "scores = cross_val_score(svm_clf, X_train, y_train, cv=4, \n",
    "                         n_jobs=-1, scoring=\"accuracy\")\n",
    "print('Accuracy_Scores:', scores)\n",
    "print('Avg_Accuracy_Score:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is actually pretty good, best so far. That's probably because under the hood, Scikit-Learn actually used the OvO strategy for SVM classifier. Let's try OVA and see if the score get's worse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_Scores: [0.79 0.77 0.81 0.91]\n",
      "Avg_Accuracy_Score: 0.8200000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "ova_svm = OneVsRestClassifier(SVC())\n",
    "scores = cross_val_score(ova_svm, X_train, y_train, cv=4, \n",
    "                         n_jobs=-1, scoring=\"accuracy\")\n",
    "print('Accuracy_Scores:', scores)\n",
    "print('Avg_Accuracy_Score:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. So far this is great.\n",
    "#### 2.iv. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_Scores: [0.81 0.83 0.8  0.84]\n",
      "Avg_Accuracy_Score: 0.8200000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "scores = cross_val_score(rf_clf, X_train, y_train, cv=4, \n",
    "                         n_jobs=-1, scoring=\"accuracy\")\n",
    "print('Accuracy_Scores:', scores)\n",
    "print('Avg_Accuracy_Score:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_Scores: [0.8  0.83 0.79 0.85]\n",
      "Avg_Accuracy_Score: 0.8175\n"
     ]
    }
   ],
   "source": [
    "ovo_rf = OneVsOneClassifier(rf_clf)\n",
    "scores = cross_val_score(ovo_rf, X_train, y_train, cv=4, \n",
    "                         n_jobs=-1, scoring=\"accuracy\")\n",
    "print('Accuracy_Scores:', scores)\n",
    "print('Avg_Accuracy_Score:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
